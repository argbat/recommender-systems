{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Práctico 2: Recomendación de videojuegos\n",
    "\n",
    "En este práctico trabajaremos con un subconjunto de datos sobre [videojuegos de Steam](http://cseweb.ucsd.edu/~jmcauley/datasets.html#steam_data). Para facilitar un poco el práctico, se les dará el conjunto de datos previamente procesado. En este mismo notebook mostraremos el proceso de limpieza, para que quede registro del proceso (de todas maneras, por el tamaño de los datos no recomendamos que pierdan tiempo en el proceso salvo que lo consideren útil a fines personales). \n",
    "\n",
    "El conjunto de datos se basa en dos partes: lista de juegos (items), y lista de reviews de usuarios sobre distintos juegos. Este último, en su versión original es muy grande, (pesa 1.3GB), por lo que será solo una muestra del mismo sobre la que trabajarán.\n",
    "\n",
    "A diferencia del conjunto de datos de LastFM utilizados en el [Práctico 1](./practico1.ipynb), en este caso los datos no están particularmente pensados para un sistema de recomendación, por lo que requerirá de un poco más de trabajo general sobre el dataset.\n",
    "\n",
    "La idea es que, de manera similar al práctico anterior, realicen un sistema de recomendación. A diferencia del práctico anterior, este será un poco más completo y deberán hacer dos sistemas, uno que, dado un nombre de usuario le recomiende una lista de juegos, y otro que dado el título de un juego, recomiende una lista de juegos similares. Además, en este caso se requiere que el segundo sistema (el que recomienda juegos basado en el nombre de un juego en particular) haga uso de la información de contenido (i.e. o bien harán un filtrado basado en contenido o algo híbrido)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Obtención y limpieza del conjunto de datos\n",
    "\n",
    "El conjunto de datos originalmente se encuentra en archivos que deberían ser de formato \"JSON\". Sin embargo, en realidad es un archivo donde cada línea es un objeto de JSON. Hay un problema no obstante y es que las líneas están mal formateadas, dado que no respetan el estándar JSON de utilizar comillas dobles (**\"**) y en su lugar utilizan comillas simples (**'**). Afortunadamente, se pueden evaluar como diccionarios de Python, lo cuál permite trabajarlos directamente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conjunto de datos limpio\n",
    "\n",
    "Para descargar el conjunto de datos que se utilizará en el práctico, basta con ejecutar la siguiente celda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process is interrupted.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "mkdir -p data/steam/\n",
    "curl -L -o data/steam/games.json.gz https://cs.famaf.unc.edu.ar/\\~ccardellino/diplomatura/games.json.gz\n",
    "curl -L -o data/steam/reviews.json.gz https://cs.famaf.unc.edu.ar/\\~ccardellino/diplomatura/reviews.json.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 1: Análisis Exploratorio de Datos\n",
    "\n",
    "Ya teniendo los datos, podemos cargarlos y empezar con el práctico. Antes que nada vamos a hacer una exploración de los datos. Lo principal a tener en cuenta para este caso es que debemos identificar las variables con las que vamos a trabajar. A diferencia del práctico anterior, este conjunto de datos no está documentado, por lo que la exploración es necesaria para poder entender que cosas van a definir nuestro sistema de recomendación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Características del conjunto de datos sobre videojuegos\n",
    "\n",
    "Las características del conjunto de datos de videojuegos tienen la información necesaria para hacer el \"vector de contenido\" utilizado en el segundo sistema de recomendación. Su tarea es hacer un análisis sobre dicho conjunto de datos y descartar aquella información redundante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "games = pd.read_json(\"./data/steam/games.json.gz\")\n",
    "games.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Completar\n",
    "content_based_df = games.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(content_based_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "publisher          8052\n",
       "genres             3283\n",
       "app_name              2\n",
       "title              2050\n",
       "release_date       2067\n",
       "tags                163\n",
       "discount_price    31910\n",
       "specs               670\n",
       "price              1377\n",
       "early_access          0\n",
       "id                    2\n",
       "developer          3299\n",
       "sentiment          7182\n",
       "metascore         29458\n",
       "dtype: int64"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content_based_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Chequemas columnas con NaN en relacion al total\n",
    "col_nan_map = {}\n",
    "for col in content_based_df.columns:\n",
    "    col_nan_map[col] = len(content_based_df[content_based_df[col].isnull()].index) / len(content_based_df.index)\n",
    "len(col_nan_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('early_access', 0.0),\n",
       " ('app_name', 6.223743581764431e-05),\n",
       " ('id', 6.223743581764431e-05),\n",
       " ('tags', 0.005072351019138012),\n",
       " ('specs', 0.020849540998910846),\n",
       " ('price', 0.04285047456044811),\n",
       " ('title', 0.06379337171308543),\n",
       " ('release_date', 0.0643223899175354),\n",
       " ('genres', 0.10216275089466315),\n",
       " ('developer', 0.1026606503812043),\n",
       " ('sentiment', 0.22349463202116074),\n",
       " ('publisher', 0.250567916601836),\n",
       " ('metascore', 0.916695192158083),\n",
       " ('discount_price', 0.992998288470515)]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted([(k,v) for k, v in col_nan_map.items()], key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descartamos las columnas metascore; discount_price la podemos convertir a dos columnas...\n",
    "# wih_discount y with_out_discount\n",
    "content_based_df=content_based_df.drop(['metascore'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    225.000000\n",
       "mean      11.930533\n",
       "std       17.492643\n",
       "min        0.490000\n",
       "25%        1.390000\n",
       "50%        4.190000\n",
       "75%       22.660000\n",
       "max      139.990000\n",
       "Name: discount_price, dtype: float64"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convertimos discount_price a dos columnas wih_discount y with_out_discount\n",
    "content_based_df['discount_price'].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "content_based_df['with_discount']=content_based_df.apply(lambda x: 1 if x['discount_price'] != math.nan else 0, axis=1)\n",
    "content_based_df['with_out_discount']=content_based_df.apply(lambda x: 0 if x['discount_price'] != math.nan else 1, axis=1)\n",
    "content_based_df=content_based_df.drop('discount_price', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# descartamos titulo, app_name, release_date (esto es subjetivo) y sentiment (no es contenido es provisto por el usuario).\n",
    "content_based_df=content_based_df.drop(['title', 'app_name', 'release_date', 'sentiment'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# descartamos columna developer\n",
    "content_based_df=content_based_df.drop('developer', 1)\n",
    "# decartamos filas con NaN en id y publisher\n",
    "content_based_df=content_based_df.dropna(subset=['id', 'publisher'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a price la descartamos.\n",
    "content_based_df=content_based_df.drop('price', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tanto tags, specs y genres tienen valores que se solapan, vamos a quedarnos con valores unicos y a esos hacerles one hot encodig.\n",
    "def to_genres_tag_specs(x):\n",
    "    genres_tag_specs = []\n",
    "    for col in ['genres', 'tags', 'specs']:\n",
    "        if type(x[col]) is list:\n",
    "            genres_tag_specs.extend(x[col])\n",
    "    genres_tag_specs = [x.lower() for x in genres_tag_specs]\n",
    "    result = set()\n",
    "    for item in genres_tag_specs:\n",
    "        result.add(item)\n",
    "    return sorted(list(result))\n",
    "content_based_df['genres_tag_specs']=content_based_df.apply(lambda x: to_genres_tag_specs(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot a la columna tags\n",
    "content_based_df = content_based_df.join(content_based_df['genres_tag_specs'].str.join('|').str.get_dummies())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_based_df=content_based_df.drop(['genres', 'tags', 'specs', 'genres_tag_specs'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8239"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# que hacemos con publisher. \n",
    "len(content_based_df['publisher'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Son 8239 publishers, convendra un embedding?, la vamos a ignorar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['publisher'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-126-3281bd9ce8ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcontent_based_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontent_based_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'publisher'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/rec-sys/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4100\u001b[0m             \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4101\u001b[0m             \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4102\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4103\u001b[0m         )\n\u001b[1;32m   4104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rec-sys/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   3912\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3913\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3914\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3915\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3916\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rec-sys/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[0;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[1;32m   3944\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3945\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3946\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3947\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3948\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rec-sys/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   5338\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5339\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5340\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{} not found in axis\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5341\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5342\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['publisher'] not found in axis\""
     ]
    }
   ],
   "source": [
    "content_based_df=content_based_df.drop('publisher', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot early access.\n",
    "content_based_df['with_early_access']=content_based_df.apply(lambda x: 1 if x['early_access'] == True else 0, axis=1)\n",
    "content_based_df['with_out_early_access']=content_based_df.apply(lambda x: 0 if x['early_access'] == False else 1, axis=1)\n",
    "content_based_df=content_based_df.drop('early_access', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chequeamos que no queda nada con valores faltantes.\n",
    "content_based_df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>with_discount</th>\n",
       "      <th>with_out_discount</th>\n",
       "      <th>1980s</th>\n",
       "      <th>1990's</th>\n",
       "      <th>2.5d</th>\n",
       "      <th>2d</th>\n",
       "      <th>2d fighter</th>\n",
       "      <th>3d platformer</th>\n",
       "      <th>3d vision</th>\n",
       "      <th>...</th>\n",
       "      <th>web publishing</th>\n",
       "      <th>werewolves</th>\n",
       "      <th>western</th>\n",
       "      <th>word game</th>\n",
       "      <th>world war i</th>\n",
       "      <th>world war ii</th>\n",
       "      <th>wrestling</th>\n",
       "      <th>zombies</th>\n",
       "      <th>with_early_access</th>\n",
       "      <th>with_out_early_access</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>761140.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>643980.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>670290.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>767400.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>772540.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 371 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  with_discount  with_out_discount  1980s  1990's  2.5d  2d  \\\n",
       "0  761140.0              1                  0      0       0     0   0   \n",
       "1  643980.0              1                  0      0       0     0   1   \n",
       "2  670290.0              1                  0      0       0     0   0   \n",
       "3  767400.0              1                  0      0       0     0   0   \n",
       "5  772540.0              1                  0      0       0     0   0   \n",
       "\n",
       "   2d fighter  3d platformer  3d vision  ...  web publishing  werewolves  \\\n",
       "0           0              0          0  ...               0           0   \n",
       "1           0              0          0  ...               0           0   \n",
       "2           0              0          0  ...               0           0   \n",
       "3           0              0          0  ...               0           0   \n",
       "5           0              0          0  ...               0           0   \n",
       "\n",
       "   western  word game  world war i  world war ii  wrestling  zombies  \\\n",
       "0        0          0            0             0          0        0   \n",
       "1        0          0            0             0          0        0   \n",
       "2        0          0            0             0          0        0   \n",
       "3        0          0            0             0          0        0   \n",
       "5        0          0            0             0          0        0   \n",
       "\n",
       "   with_early_access  with_out_early_access  \n",
       "0                  0                      0  \n",
       "1                  0                      0  \n",
       "2                  0                      0  \n",
       "3                  0                      0  \n",
       "5                  0                      0  \n",
       "\n",
       "[5 rows x 371 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content_based_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# guardamos un mapa de indice-id\n",
    "content_based_id_idx = dict(zip(content_based_df['id'], list(content_based_df.index)))\n",
    "content_based_df=content_based_df.drop('id', 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Características del conjunto de datos de reviews\n",
    "\n",
    "Este será el conjunto de datos a utilizar para obtener información sobre los usuarios y su interacción con videojuegos. Como se puede observar no hay un rating explícito, sino uno implícito a calcular, que será parte de su trabajo (deberán descubrir que característica les puede dar información que puede ser equivalente a un rating)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>product_id</th>\n",
       "      <th>page_order</th>\n",
       "      <th>text</th>\n",
       "      <th>hours</th>\n",
       "      <th>products</th>\n",
       "      <th>date</th>\n",
       "      <th>early_access</th>\n",
       "      <th>page</th>\n",
       "      <th>compensation</th>\n",
       "      <th>found_funny</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>SPejsMan</td>\n",
       "      <td>227940</td>\n",
       "      <td>0</td>\n",
       "      <td>Just one word... Balance!</td>\n",
       "      <td>23.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>2015-02-25</td>\n",
       "      <td>True</td>\n",
       "      <td>3159</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Spodermen</td>\n",
       "      <td>270170</td>\n",
       "      <td>4</td>\n",
       "      <td>Graphics: none\\nMusic: Makes me want to sleep\\...</td>\n",
       "      <td>4.9</td>\n",
       "      <td>217.0</td>\n",
       "      <td>2014-08-26</td>\n",
       "      <td>False</td>\n",
       "      <td>231</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.656120e+16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>josh</td>\n",
       "      <td>41700</td>\n",
       "      <td>1</td>\n",
       "      <td>cheeki breeki iv danke, stalker</td>\n",
       "      <td>53.2</td>\n",
       "      <td>78.0</td>\n",
       "      <td>2015-12-25</td>\n",
       "      <td>False</td>\n",
       "      <td>191</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Sammyrism</td>\n",
       "      <td>332310</td>\n",
       "      <td>9</td>\n",
       "      <td>I am really underwhelmed by the small about of...</td>\n",
       "      <td>16.2</td>\n",
       "      <td>178.0</td>\n",
       "      <td>2015-06-04</td>\n",
       "      <td>True</td>\n",
       "      <td>570</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>moonmirroir</td>\n",
       "      <td>303210</td>\n",
       "      <td>9</td>\n",
       "      <td>I came into the game expecting nothing, of cou...</td>\n",
       "      <td>1.8</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2015-10-02</td>\n",
       "      <td>False</td>\n",
       "      <td>967</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      username  product_id  page_order  \\\n",
       "0     SPejsMan      227940           0   \n",
       "1    Spodermen      270170           4   \n",
       "2         josh       41700           1   \n",
       "3    Sammyrism      332310           9   \n",
       "4  moonmirroir      303210           9   \n",
       "\n",
       "                                                text  hours  products  \\\n",
       "0                          Just one word... Balance!   23.0      92.0   \n",
       "1  Graphics: none\\nMusic: Makes me want to sleep\\...    4.9     217.0   \n",
       "2                    cheeki breeki iv danke, stalker   53.2      78.0   \n",
       "3  I am really underwhelmed by the small about of...   16.2     178.0   \n",
       "4  I came into the game expecting nothing, of cou...    1.8      13.0   \n",
       "\n",
       "        date  early_access  page compensation  found_funny       user_id  \n",
       "0 2015-02-25          True  3159         None          NaN           NaN  \n",
       "1 2014-08-26         False   231         None          NaN  7.656120e+16  \n",
       "2 2015-12-25         False   191         None          NaN           NaN  \n",
       "3 2015-06-04          True   570         None          NaN           NaN  \n",
       "4 2015-10-02         False   967         None          NaN           NaN  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews = pd.read_json(\"./data/steam/reviews.json.gz\")\n",
    "reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5920185714285714\n"
     ]
    }
   ],
   "source": [
    "# Completar\n",
    "# q es user_id?\n",
    "print(reviews['user_id'].isnull().sum()/len(reviews['user_id'].index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 59% no tiene user_id ... creamo uno propio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(reviews['username'].isnull().sum()/len(reviews['username'].index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "username_unique = reviews.drop_duplicates(subset = ['username'], keep = 'first')['username'].to_dict()\n",
    "my_id_username_map = {v: k for k, v in username_unique.items()}\n",
    "reviews = reviews.drop(['user_id'] , axis = 1)    \n",
    "reviews.insert(0, 'user_id', reviews.username.map(my_id_username_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(reviews['product_id'].isnull().sum()/len(reviews['product_id'].index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0034885714285714286\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# NaN en horas, lo usaremos como un rating.\n",
    "print(reviews['hours'].isnull().sum()/len(reviews['hours'].index))\n",
    "reviews=reviews.dropna(subset=['hours'])\n",
    "print(reviews['hours'].isnull().sum()/len(reviews['hours'].index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remover casos donde un mismo usr dejo mas de una review para un producto.\n",
    "reviews=reviews.drop_duplicates(subset=['user_id', 'product_id'], keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "min_max_scaler = MinMaxScaler()\n",
    "hours_norm = min_max_scaler.fit_transform(reviews.hours.values.reshape(-1, 1))\n",
    "reviews['hours_norm'] = hours_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "688760"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reviews.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>username</th>\n",
       "      <th>product_id</th>\n",
       "      <th>page_order</th>\n",
       "      <th>text</th>\n",
       "      <th>hours</th>\n",
       "      <th>products</th>\n",
       "      <th>date</th>\n",
       "      <th>early_access</th>\n",
       "      <th>page</th>\n",
       "      <th>compensation</th>\n",
       "      <th>found_funny</th>\n",
       "      <th>hours_norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>76782</td>\n",
       "      <td>76782</td>\n",
       "      <td>SIMPERISMO</td>\n",
       "      <td>319630</td>\n",
       "      <td>8</td>\n",
       "      <td>Nice Game with a very nice Story.</td>\n",
       "      <td>19.1</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2017-08-27</td>\n",
       "      <td>False</td>\n",
       "      <td>412</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98957</td>\n",
       "      <td>98957</td>\n",
       "      <td>j.toohey</td>\n",
       "      <td>391540</td>\n",
       "      <td>4</td>\n",
       "      <td>BEST GAME EVER</td>\n",
       "      <td>31.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2016-06-09</td>\n",
       "      <td>False</td>\n",
       "      <td>2661</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>289361</td>\n",
       "      <td>289361</td>\n",
       "      <td>Civhawk</td>\n",
       "      <td>252490</td>\n",
       "      <td>7</td>\n",
       "      <td>Great game i really thing you should pick it u...</td>\n",
       "      <td>553.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>2014-01-13</td>\n",
       "      <td>True</td>\n",
       "      <td>9686</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.029778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>185338</td>\n",
       "      <td>185338</td>\n",
       "      <td>kijji</td>\n",
       "      <td>240760</td>\n",
       "      <td>7</td>\n",
       "      <td>This is the first CRPG (computer role-playing ...</td>\n",
       "      <td>107.8</td>\n",
       "      <td>163.0</td>\n",
       "      <td>2014-09-25</td>\n",
       "      <td>False</td>\n",
       "      <td>344</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>431782</td>\n",
       "      <td>431782</td>\n",
       "      <td>francescorenCSGO500</td>\n",
       "      <td>273110</td>\n",
       "      <td>2</td>\n",
       "      <td>for the people never played the csgo you will ...</td>\n",
       "      <td>799.3</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2016-06-07</td>\n",
       "      <td>False</td>\n",
       "      <td>331</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.043040</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id             username  product_id  page_order  \\\n",
       "76782     76782           SIMPERISMO      319630           8   \n",
       "98957     98957             j.toohey      391540           4   \n",
       "289361   289361              Civhawk      252490           7   \n",
       "185338   185338                kijji      240760           7   \n",
       "431782   431782  francescorenCSGO500      273110           2   \n",
       "\n",
       "                                                     text  hours  products  \\\n",
       "76782                   Nice Game with a very nice Story.   19.1      24.0   \n",
       "98957                                      BEST GAME EVER   31.2       2.0   \n",
       "289361  Great game i really thing you should pick it u...  553.0      60.0   \n",
       "185338  This is the first CRPG (computer role-playing ...  107.8     163.0   \n",
       "431782  for the people never played the csgo you will ...  799.3      15.0   \n",
       "\n",
       "             date  early_access  page compensation  found_funny  hours_norm  \n",
       "76782  2017-08-27         False   412         None          NaN    0.001028  \n",
       "98957  2016-06-09         False  2661         None          NaN    0.001680  \n",
       "289361 2014-01-13          True  9686         None          1.0    0.029778  \n",
       "185338 2014-09-25         False   344         None          NaN    0.005805  \n",
       "431782 2016-06-07         False   331         None          NaN    0.043040  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews = reviews.sample(n=1000, random_state=47)\n",
    "reviews.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 2 - Sistema de Recomendación Basado en Usuarios\n",
    "\n",
    "Este sistema de recomendación deberá entrenar un algoritmo y desarrollar una interfaz que, dado un usuario, le devuelva una lista con los juegos más recomendados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Completar\n",
    "from surprise import Reader\n",
    "from surprise import Dataset\n",
    "from surprise import NormalPredictor\n",
    "from surprise import KNNWithMeans\n",
    "from surprise import KNNWithZScore\n",
    "from surprise.accuracy import rmse, mae\n",
    "from surprise import accuracy\n",
    "from surprise.model_selection import cross_validate\n",
    "from surprise.model_selection import train_test_split\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = Reader(rating_scale=(numpy.amin(reviews['hours_norm']), \n",
    "                              numpy.amax(reviews['hours_norm'])))\n",
    "data = Dataset.load_from_df(reviews[['user_id', 'product_id', 'hours_norm']], reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    }
   ],
   "source": [
    "trainset = data.build_full_trainset()\n",
    "model = KNNWithZScore(sim_options={'name': 'pearson', 'user_based': True})\n",
    "model.fit(trainset)\n",
    "testset = trainset.build_anti_testset()\n",
    "predictions = model.test(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def predictions_per_users(predictions):\n",
    "    pedictions_per_users = {}\n",
    "    for user_id, item_id, _, est, _ in predictions:\n",
    "        try:\n",
    "            pedictions_per_users[user_id].append((item_id, est))\n",
    "        except:\n",
    "            pedictions_per_users[user_id] = []\n",
    "            pedictions_per_users[user_id].append((item_id, est))\n",
    "    return pedictions_per_users\n",
    "\n",
    "def best_predictions_per_users(pedictions_per_user, top_n):\n",
    "    best_pedictions_per_users = {}\n",
    "    for user_id, user_predicted_ratings in pedictions_per_user.items():\n",
    "        user_predicted_ratings.sort(key = lambda x: x[1], reverse = True)\n",
    "        best_pedictions_per_users[user_id] = user_predicted_ratings[:top_n]\n",
    "    return best_pedictions_per_users\n",
    "    \n",
    "best_predictions_per_users = best_predictions_per_users(predictions_per_users(predictions), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_predictions_for_user(user_name, best_predictions_per_user):\n",
    "    user_id = reviews[reviews['username'].str.lower() == user_name.lower()]['user_id'].values[0]\n",
    "    print(user_name, user_id)\n",
    "    for product_id, _ in best_predictions_per_user[user_id]:\n",
    "        print(games[games['id'] == product_id][['title']].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kijji 185338\n",
      "['Vector']\n",
      "['DARK SOULS™: Prepare To Die™ Edition']\n",
      "[\"Jets'n'Guns Gold\"]\n",
      "['Bloodwood Reload']\n",
      "['Darksiders II Deathinitive Edition']\n"
     ]
    }
   ],
   "source": [
    "best_predictions_for_user('kijji', best_predictions_per_users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 3 - Sistema de Recomendación Basado en Juegos\n",
    "\n",
    "Similar al caso anterior, con la diferencia de que este sistema espera como entrada el nombre de un juego y devuelve una lista de juegos similares. El sistema deberá estar programado en base a información de contenido de los juegos (i.e. filtrado basado en contenido o sistema híbrido)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'content_based_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-106-68dd9d4f4556>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Completar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpairwise\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcosine_similarity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mcosine_sim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcosine_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent_based_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent_based_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'content_based_df' is not defined"
     ]
    }
   ],
   "source": [
    "# Completar\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "cosine_sim = cosine_similarity(content_based_df, content_based_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similar_games_by_content(game_title, nb_of_recommendations):\n",
    "    game_id = games[games['title'].str.lower() == game_title.lower()]['id'].values[0]\n",
    "    game_idx = dict(zip(games['id'], list(games.index)))\n",
    "    idx = game_idx[game_id]\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    sim_scores = sim_scores[1:(nb_of_recommendations+1)]\n",
    "    similar = [i[0] for i in sim_scores]\n",
    "    return games['title'].iloc[similar].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_title = 'Lost Summoner Kitty'\n",
    "print(similar_games_by_content(game_title, 5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "rise": {
   "scroll": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
